---
permalink: /
title: Biography
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<p style="line-height:1.5" align="justify">
    <font size="3.5">
        Currently, I am a last year Phd student studying Computer Science at Durham University and advised by Prof. <a href="https://www.durham.ac.uk/staff/yang-long/">Yang Long</a>. My current research lies at the intersection of computer vision, computer graphics, and machine learning, focusing on understanding the dynamic three-dimensional world as captured by everyday images and videos. By moving beyond the limitations of traditional 2D or 2.5D representations, I strive to develop multi-view reconstruction techniques that offer a comprehensive understanding of complex environments. Ultimately, my long-term goal is to create intelligent systems capable of perceiving, interpreting, and continually learning from the ever-evolving physical world.
    </font>
</p>

News
------

<p style="line-height:1.5">
    <font size="3">
        [2025.07] Two papers are accepted to BMVC 2025, congrating to Xueqi and Tianyu. <br>
        [2025.06] One paper is accepted to ICCV 2025. <br>
        [2025.06] One paper is accepted to MICCAI 2025, congrating to Minye. <br>
        [2025.05] One paper is accepted to ICML 2025. <br>
        [2025.01] One paper is accepted to TPAMI 2025. <br>
        [2024.08] One paper is accepted to PR 2024. <br>
        [2023.08] One paper is accepted to TCSVT 2023.
    </font>
</p>

Selected Publications
------
<table style="border-collapse: collapse; border: none;">
  <tr>
    <td style="padding:5px; width:22%; vertical-align:middle; border: none;">
      <img src="../images/M2StyleGS.png" width="150" height="150" alt="M2StyleGS">
    </td>
    <td style="padding:5px; width:78%; vertical-align:middle; border: none;">
      <h3 id="M2StyleGS">
        <font size="3">
          M<sup>2</sup>StyleGS: Multi-Modality 3D Style Transfer with Gaussian Splatting
        </font>
      </h3>
      <p style="line-height:1.0;">
        <font size="2">
          <strong>Xingyu Miao<sup>*</sup></strong>, Xueqi Qiu<sup>*</sup>, Haoran Duan, Yawen Huang, Xian Wu, Jingjing Deng, Yang Long <br>
          <i>British Machine Vision Conference (<strong>BMVC</strong>), 2025 <span style="color: red;">(Oral Presentaion)</span><br></i>
          <a href="">Paper</a> | 
          <a href="">Code</a><br>
        </font>
      </p>
    </td>
  </tr>
</table>
<hr>

<table style="border-collapse: collapse; border: none;">
  <tr>
    <td style="padding:5px; width:22%; vertical-align:middle; border: none;">
      <img src="../images/2D-to-3D.png" width="150" height="150" alt="2D-to-3D">
    </td>
    <td style="padding:5px; width:78%; vertical-align:middle; border: none;">
      <h3 id="2D-to-3D">
        <font size="3">
          Towards Scalable Spatial Intelligence via 2D-to-3D Data Lifting
        </font>
      </h3>
      <p style="line-height:1.0;">
        <font size="2">
          <strong>Xingyu Miao</strong>, Haoran Duan, Quanhao Qian, Jiuniu Wang, Yang Long, Ling Shao, Deli Zhao, Ran Xu, Gongjie Zhang<br>
          <i>International Conference on Computer Vision (<strong>ICCV</strong>), 2025 <span style="color: red;">(Highlight)</span><br></i>
          <a href="https://arxiv.org/abs/2507.18678">Paper</a> | 
          <a href="https://zhanggongjie.github.io/TowardsSSI-page/">Code</a><br>
        </font>
      </p>
    </td>
  </tr>
</table>
<hr>


<table style="border-collapse: collapse; border: none;">
  <tr>
    <td style="padding:5px; width:22%; vertical-align:middle; border: none;">
      <img src="../images/uds.png" width="150" height="150" alt="UDS">
    </td>
    <td style="padding:5px; width:78%; vertical-align:middle; border: none;">
      <h3 id="UDS">
        <font size="3">
          Rethinking Score Distilling Sampling for 3D Editing and Generation
        </font>
      </h3>
      <p style="line-height:1.0;">
        <font size="2">
          <strong>Xingyu Miao</strong>, Haoran Duan, Yang Long, Jungong Han<br>
          <i>International Conference on Machine Learning (<strong>ICML</strong>), 2025<br></i>
          <a href="https://arxiv.org/abs/2505.01888">Paper</a> | 
          <a href="https://github.com/xingy038/UDS">Code</a><br>
        </font>
      </p>
    </td>
  </tr>
</table>
<hr>

<table style="border-collapse: collapse; border: none;">
  <tr>
    <td style="padding:5px; width:22%; vertical-align:middle; border: none;">
      <img src="../images/laser.png" width="150" height="150" alt="Laser">
    </td>
    <td style="padding:5px; width:78%; vertical-align:middle; border: none;">
      <h3 id="Laser">
        <font size="3">
          Laser: Efficient Language-Guided Segmentation in Neural Radiance Fields
        </font>
      </h3>
      <p style="line-height:1.0;">
        <font size="2">
          <strong>Xingyu Miao</strong>, Haoran Duan, Yang Bai, Tejal Shah, Jun Song, Yang Long, Rajiv Ranjan, Ling Shao<br>
          <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2025<br></i>
          <a href="https://arxiv.org/abs/2501.19084">Paper</a> | 
          <a href="https://github.com/xingy038/Laser">Code</a><br>
        </font>
      </p>
    </td>
  </tr>
</table>
<hr>

<table style="border-collapse: collapse; border: none;">
  <tr>
    <td style="padding:5px; width:22%; vertical-align:middle; border: none;">
      <img src="../images/ctnerf.png" width="150" height="150" alt="CTNeRF">
    </td>
    <td style="padding:5px; width:78%; vertical-align:middle; border: none;">
      <h3 id="CTNeRF">
        <font size="3">
          CTNeRF: Cross-Time Transformer for Dynamic Neural Radiance Field from Monocular Video
        </font>
      </h3>
      <p style="line-height:1.0;">
        <font size="2">
          <strong>Xingyu Miao</strong>, Yang Bai, Haoran Duan, Yawen Huang, Fan Wan, Yang Long, Yefeng Zheng<br>
          <i>Pattern Recognition (<strong>PR</strong>), 2024<br></i>
          <a href="https://arxiv.org/abs/2401.04861">Paper</a> | 
          <a href="https://github.com/xingy038/CTNeRF">Code</a><br>
        </font>
      </p>
    </td>
  </tr>
</table>
<hr>

<table style="border-collapse: collapse; border: none;">
  <tr>
    <td style="padding:5px; width:22%; vertical-align:middle; border: none;">
      <img src="../images/ds-depth.png" width="150" height="150" alt="DS-Depth">
    </td>
    <td style="padding:5px; width:78%; vertical-align:middle; border: none;">
      <h3 id="DS-Depth">
        <font size="3">
          DS-Depth: Dynamic and Static Depth Estimation via a Fusion Cost Volume
        </font>
      </h3>
      <p style="line-height:1.0;">
        <font size="2">
          <strong>Xingyu Miao</strong>, Yang Bai, Haoran Duan, Yawen Huang, Fan Wan, Xinxing Xu, Yang Long, Yefeng Zheng<br>
          <i>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>), 2023<br></i>
          <a href="https://arxiv.org/abs/2308.07225">Paper</a> | 
          <a href="https://github.com/xingy038/DS-Depth">Code</a><br>
        </font>
      </p>
    </td>
  </tr>
</table>
<hr>